%!TEX root = tese/main.tex
%% USPSC-Abstract.tex
%\autor{Silva, M. J.}
\begin{resumo}[Abstract]
 \begin{otherlanguage*}{english}
	\begin{flushleft} 
		\setlength{\absparsep}{0pt} % ajusta o espaçamento dos parágrafos do resumo		
 		\SingleSpacing  		\imprimirautorabr~~\textbf{\imprimirtitleabstract}.	\imprimirdata.  \pageref{LastPage} p. 
		%Substitua p. por f. quando utilizar oneside em \documentclass
		%\pageref{LastPage} f.
		\imprimirtipotrabalhoabs~-~\imprimirinstituicao, \imprimirlocal, 	\imprimirdata. 
 	\end{flushleft}
	\OnehalfSpacing 
	This study addresses the growing issue of ``adultification'' and sexualization of minors on social networks, driven by the pursuit of engagement and monetization. 
	The primary objective was to develop a proof of concept for a web browser extension, utilizing the Manifest V3 architecture, capable of automatically identifying and hiding sexualized content involving children on the Instagram platform. 
	The methodology was based on the integration of multimodal Large Language Models (LLMs) via REST API, specifically testing Gemini 2.5 Flash and the Llama 4 variants (Scout and Maverick), for the analysis of posts. 
	Systematic testing of prompt engineering and temperature was conducted to optimize detection accuracy and recall. 
	The results demonstrated that the Llama 4 Scout model achieved the best performance, reaching 95\% accuracy with an average response time of under 1.5 seconds. 
	It is concluded that the utilization of multimodal agents is technically viable and effective in mitigating exposure to inappropriate content, offering a proactive tool for the digital safety of minors.

   \vspace{\onelineskip}
 
   \noindent 
   \textbf{Keywords}: Artificial Intelligence. Web Development. Social Networks. Child Sexualization. Browser Extension. Multimodal LLMs.
 \end{otherlanguage*}
\end{resumo}
