%!TEX root = tese/main.tex
\chapter{Revisão bibliográfica} \label{chap:revisao_bibliografica}
Aqui é apresentada a fundamentação teórica do trabalho, 
por meio da análise de estudos prévios dos temas relevantes para o desenvolvimento do projeto e 
que embasam a justificativa das metodologias adotadas.

\section{Estudos sobre ``adultização'' nas redes sociais}
Atualmente, é amplamente estudado na literatura como as redes sociais impactam o crescimento de crianças.
Em muitos ambientes \textit{online}, não há restrições realmente eficientes ao acesso da criança em relação ao de um adulto:
elas podem, sem grandes dificuldades, utilizar ferramentas de buscas livremente, participar de interações sociais, e fazer \textit{download} e \textit{upload} de conteúdos, por exemplo.
Esse contato precoce com uma quantidade grande de informações pode impactar a psicologia e personalidade da criança,
levando a problemas de saúde mental, sentimentos de solidão, violentos ou de indiferença \cite{zheng2022}.

O estudo de \citeonline{yao2024}, realizado na China, analisou 2000 vídeos contendo crianças retirados de redes sociais como TikTok e Kwai, e outros 2000 contendo adultos.
Ao final, o estudo concluiu não só que ocorre a adultização das crianças, mas também a infantilização dos adultos. 
Nessa pesquisa, características identificadas como adultização foram, por exemplo, 
roupas reveladoras, e palavras e comportamentos sugestivos. 
\citeonline{yao2024} apontou como motivo para o fenômeno o rompimento do isolamento entre o virtual e o real, 
permitindo que as crianças participem do mundo adulto.

Esses e outros estudos \cite{orman2020, cabezas2022} mostram que de fato é um consenso na literatura que o consumo e exposição precoce no mundo digital pode impactar negativamente o desenvolvimento de um ser humano,
levando, em alguns casos, a uma ``adultização'' acelerada e descontrolada.  

\section{Revisão de modelos para detecção de sexualização} \label{sec:revisao_deteccao_sexualizacao}
Há uma grande gama de modelos de IA, principalmente redes neurais de aprendizado profundo, voltadas à identificação de conteúdos sexualmente explícitos \footnote{10 APIs detectoras de conteúdos explicitos: \url{https://www.edenai.co/post/top-10-explicit-content-detection-apis}}.
Tais modelos muitas vezes podem ser acessados por APIs e funcionam calculando a probabilidade do conteúdo passado ser explícito e comparam com um valor limite pré-definido para definir se trata-se ou não.

Esse tipo de conteúdo comumente é chamado de NSFW (\textit{Not Suitable For Work}) 
e APIs como a da Clarifai\footnote{API de NSFW da Clarifai: \url{https://clarifai.com/clarifai/main/models/nsfw-recognition}}
ou a detecção SafeSearch integrada ao Google Cloud\footnote{SafeSearch: \url{https://docs.cloud.google.com/vision/docs/detecting-safe-search?hl=pt-br}}
foram treinadas com milhares de imagens e podem analisar a explecitude em relação a diferentes rótulos além de nudez, 
como violência, drogas ou médico. 
Além disso, muitos desses modelos podem classificar diferentes níveis de nudez, como apenas algo apenas sugestivo ou totalmete explícito.

Porém, a aplicação desse projeto expõe certas limitações e restrições sobre o uso dessas APIs:
\begin{itemize}
    \item As postagens do Instagram já passam por um filtro prévio feito por redes neurais convolucionais \cite{mohiuddin2024}, assim conteúdos totalmente explícitos já não irão aparecer.
    Portanto, a API utilizada precisa conseguir identificar conteúdos levemente sugestivos, e não só os totalmente explícitos.
    \item Já que a ideia não é fazer um produto final que gera alguma renda, restringe-se ao uso de APIs gratuitas.
    \item Como o próprio Felca expõe em seu vídeo, muitas vezes os pedófilos enxergam uma visão destorcida da realidade, 
    vendo interesse em publicações que a olhos normais não são sugestivos. 
    Isso exige uma precisão na identificação dos conteúdos que torna conveniente o uso de linguagem natural para comunicação com o modelo.
\end{itemize}

Limitando-se aos modelos gratuitos, 
como o \texttt{nsfw-cateforize.it}\footnote{\url{https://nsfw-categorize.it/}} 
(que possui cota gratuita de apenas 10 imagens por dia),
ou o \textit{open source} \texttt{nsfw\_image\_detection}\footnote{\url{https://huggingface.co/Falconsai/nsfw_image_detection}} 
(que não diferencia diferentes níveis de nudez)
as restrições ficam ainda mais difíceis de contornar. 

\section{Revisão de modelos para identificação de crianças} \label{sec:revisao_identificacao_criancas}
O projeto não visa simplesmente identificar a presença de conteúdo sugestivamente sexual, 
mas sim identificar isso ligado especificamente a crianças. 
Portanto, no caso de seguir a abordagem de redes neurais, 
seria necessário de alguma forma combinar uma rede para identificação da explicitude (abordado na \autoref{sec:revisao_deteccao_sexualizacao})
com uma para identificação de crianças.

Recorrendo à literatura, é difícil encontrar um modelo robusto e confiável treinado especialmente para o reconhecimento de crianças, 
porém, são amplamente encontradas redes de reconhecimento/detecção de objetos no geral \footnote{10 APIs de detecção de objetos: \url{https://www.edenai.co/post/top-10-object-detection-apis}}.
Por exemplo, a API \texttt{general-image-recognition}\footnote{\url{https://clarifai.com/clarifai/main/models/general-image-recognition?tab=overview}} da Clarify
foi treinada com 20 milhões de imagens e é capaz de reconhecer 10 mil ``conceitos'' pré-definidos, como objetos e até temas. 
APIs de detecção muitas vezes podem delimitar na imagem os objetos contidos, como mostrado na \autoref{fig:identificacao_objetos}.

\begin{figure}[htb]
	\begin{center}
	\caption{Exemplo de detecção em imagem}
    \label{fig:identificacao_objetos}
	\includegraphics[width=0.8\textwidth]{USPSC-img/objects-detection.png} \\
	\fonte{\url{https://www.edenai.co/post/top-10-object-detection-apis}}
	\end{center}	
\end{figure}

Aqui, também há uma certa dificuldade: a delimitação de contexto utilizado para a rede.
Seria necessário utilizar o modelo de detecção de objetos para, de alguma forma, delimitar a área de análise do de conteúdo explícito.

Por exemplo, em uma imagem pode haver uma pessoa adulta em foco em uma posição sugestiva 
e, ao fundo, uma criança passando. 
Nesse exemplo, os dois modelos responderiam ``sim'', apesar de não haver exatamente sexualização infantil.
Por outro lado, se em uma imagem houverem duas crianças juntas em uma posição sugestiva, 
se enviarmos ao segundo modelo as duas crianças separadamente, pode ser que ele não identifique essa camada de sexualidade da imagem.

Portanto, conclui-se que a integração entre diferentes redes pode se tornar altamente complexa, 
ainda mais lidando com identificação de sutilezas implícitas.

\section{Por que utilizar agente multimodal}
Por conta das dificuldades relacionadas à integração entre modelos citada na \autoref{sec:revisao_identificacao_criancas}
e as dificuldades de ajuste fino expostas na \autoref{sec:revisao_deteccao_sexualizacao}, 
foi concluído que modelos multimodais, como Gemini da Google ou GPT da OpenAI seriam mais convenientes para a aplicação.

Modelos chamados ``multimodais'' se referem aos que podem receber como entrada diferentes tipos de arquivos, 
como vídeos, imagem, áudio e texto. 
Aqui refere-se especificamente aos multimodais \textit{large language models} (LLM),
que são treinados por aprendizado de máquina auto-supervisionado em uma vasta quantidade de dados 
e capazes de entender e responder em linguagem natural. 

A capacidade de se comunicar em linguagem natural e o baixo custo são o que fazem esses modelos serem tão convenientes para esse projeto.
Os ajustes para fazer a extensão identificar as sutilezas mencionadas na \autoref{sec:revisao_deteccao_sexualizacao}
podem ser realizados simplesmente por meio da passagem de exemplos e explicação em palavras para o LLM,
ao invés do ajuste de parâmetros que seria necessário no caso de lidar-se diretamente com uma rede neural.
Além disso, utilizar unicamente a LLM para identificar adultização resolve o problema da integração entre modelos. 

Mas afinal, é possível atingir uma boa acurácia deixando de escolher ferramentas específias de detecção de imagem para adotar-se uma ferramenta tão generalista?
Em um estudo de \citeonline{than2024}, 
foram comparadas as performance de várias LLMs com as de redes neurais de aprendizado profundo no contexto de detecção de tumores.
As redes neurais convolucionais foram pré-treinadas com milhões de imagens gerais e então feito um \textit{fine-tuning} com algumas centenas de imagens médicas.
Ao final, de todos os modelos testados, o que se saiu melhor em todos os critérios foi o Gemini 1.5 Pro (\autoref{fig:than_tabela_comparacao}).

\begin{table}[htb]
    \centering
    \caption{Comparação da performance dos modelos}
    \label{fig:than_tabela_comparacao}
    \begin{subfigure}[htb]{0.45\textwidth} 
        \centering
        \caption{Pré-treinados de aprendizado profundo}
        \includegraphics[width=\linewidth]{USPSC-img/performance-cnn.png}
    \end{subfigure}
    \hspace{0.02\textwidth}
    \begin{subfigure}[htb]{0.45\textwidth}
        \centering
        \caption{Multimodais}
        \includegraphics[width=\linewidth]{USPSC-img/performance-multimodal.png}
    \end{subfigure} 
    \fonte{\cite{than2024}}
\end{table}

No estudo citado, foi concluído que modelos multimodais podem performar até melhor que redes de aprendizado profundo na falta de dados suficientes de treinamento.
O artigo também destaca a possibilidade de maior explicabilidade via dos multimodais, que indicam de maneira mais intuitiva como as decisões foram feitas.
A \autoref{fig:than_explicabilidade_texto} mostra um exemplo dessa explicação em texto, 
já na \autoref{fig:than_explicabilidade_imagem} foi solicitado ao modelo gerar um mapa de calor destacando onde o tumor foi detectado.

\begin{figure}[htb]
    \centering
    \caption{Exemplos de explicabilidade}
    \label{fig:than_explicabilidade}
    \begin{subfigure}[htb]{0.45\textwidth} 
        \centering
        \caption{Explicação em texto}
        \label{fig:than_explicabilidade_texto}
        \includegraphics[width=\linewidth]{USPSC-img/explicabilidade.png}
    \end{subfigure}
    \hspace{0.02\textwidth}
    \begin{subfigure}[htb]{0.45\textwidth}
        \centering
        \caption{Explicação em imagem}
        \label{fig:than_explicabilidade_imagem}
        \includegraphics[width=\linewidth]{USPSC-img/explicabilidade-heatmap.png}
    \end{subfigure} 
    \fonte{\cite{than2024}}
\end{figure}

Enfim, como foi demonstrado, é totalmente possível utilizar modelos multimodais e consiliar uma boa acurácia com a conveniência de se comunicar com a ferramenta utilizando linguagem natural. 

\section{Comparação de APIs multimodais gratuitas disponíveis}

Como já citado como uma das restrições para o projeto na \autoref{sec:revisao_deteccao_sexualizacao},
vamos nos limitar às APIs de LLMs gratuitas, ou melhor, que pelo menos oferecem uma margem de uso gratuito suficiente para a aplicação.
Geralmente os limites de uso são dados em números de solicitações (\textit{requests}) solicitados e número de tokens utilizados.  
Nessa seção, as principais opções encontradas de provedores gratuitos são expostas.

\subsection{Cerebras}

Cerebra\footnote{\url{https://www.cerebras.ai/}} é uma empresa que fornece uma API com várias opções de modelos \textit{open source}.
Dentre os modelos, atualmente temos o GPT OSS 120B (feito pela OpenAI), alguns modelos Llama (feitos pela Meta) e alguns Qwen (Alibaba Cloud).

A Cerebra declara prover a ``infraestrutura mais rápida de IA'' do mundo. 
Isso pois ela possui um processador próprio feito com foco em IA que, segundo ela, é o mais rápido que existe.
Esse destaque pode ser observado no gráfico da \autoref{fig:cerebra_performance}.

\begin{figure}[htb]
	\begin{center}
	\caption{Comparação de performance de provedores de IA utilizando mesmo modelo}
    \label{fig:cerebra_performance}
	\includegraphics[width=0.9\textwidth]{USPSC-img/cerebra-performance.jpg} \\
	\fonte{\url{https://www.cerebras.ai/blog/cerebras-inference-3x-faster}}
	\end{center}	
\end{figure}

Porém, o que inviabiliza o uso da Cerebras é que, no momento, a sua API REST de inferência pública não suporta diretamente a entrada de imagens para modelos multimodais.
Embora a Cerebras tenha capacidade e documentação para treinar modelos multimodais como o LLaVA (que combinam visão e linguagem), a API de inferência e seus SDKs (Python, Node.js) são focados em modelos de linguagem de texto, como a família LLaMA e Qwen.

\subsection{Groq}

Assim como a Cerebra, Groq\footnote{\url{https://groq.com/}} também possui um processador proprietário focado em IA e fornece uma série de modelos \textit{open source}.
Aqui, são oferecidos ainda mais opções que a Cerebra, incluindo alguns desenvolvidos pela própria empresa.

No geral, os limites da Groq são bem mais restritivos que os da Cerebra, 
porém aqui eles disponibilizam pela API REST acesso a dois modelos multimodais, os Llama 4 Scout e Llama 4 Maverick.

\begin{table}[htb]
	\IBGEtab{%
        \caption{Limites de Uso do Llama 4 Scout pela Groq}
        \label{tab:groq_limites}
	}{%
		\begin{tabular}{lcc}
			\toprule
			Categoria & Por minuto & Por dia \\
			\midrule \midrule
			Solicitações & 0 & 1000 \\
			\midrule 
			Uso de tokens & 30 mil & 500 mil \\
			\bottomrule
		\end{tabular}%
	}{%
		\fonte{Groq}%
	}
\end{table}

\subsection{Mistral}

A Mistral\footnote{\url{https://mistral.ai/}} desenvolve os seus próprios modelos, sendo alguns \textit{open source} e outros fechados.
A performance dos seus modelos não está entre as melhores, mas os limites de uso são bem generosos. 
O Mistral Medium 3, por exemplo, possibilita o uso de 500 mil tokens por minuto e até 1 bilhão por dia, 
tornando essa API uma boa opção caso o uso de tokens for muito alto. 

\subsection{Gemini}

A Google disponibiliza uma API\footnote{\url{https://aistudio.google.com/}} para acesso aos seus modelos proprietários, que são todos códigos fechados.
Dentre os modelos do Google que possuem limite de requisições por minuto suficientemente alto para o projeto, 
o Gemini 2.5 Flash é o de melhor performance.

\begin{table}[htb]
	\IBGEtab{%
		\label{tab:gemini_limites}
		\caption{Limites do Gemini 2.5 Flash}
	}{%
		\begin{tabular}{lcc}
			\toprule
			Categoria & Limite por minuto & Limite por dia \\
			\midrule \midrule
			Solicitações & 10 & 250 \\
			\midrule 
			Uso de tokens & 250 mil & - \\
			\bottomrule
		\end{tabular}%
	}{%
		\fonte{Google}%
	}
\end{table}

De acordo com a empresa, o Gemini 2.5 Flash é 
``útil para a maioria das tarefas complexas, enquanto tem um equilibrio entre qualidade, custo e latência''.
Sendo assim, é voltado para uso geral, rodando de maneira veloz com um desempenho nas respostas não tão atrás da opção mais avançada do Gemini, a 2.5 Pro \cite{teamgoogle2025}.

Esse modelo atualmente se posiciona muito bem nos \textit{benchmarks} quando comparado a outros focados em uso geral:
está na posição mais alta no site MMMU \cite{mmmu2023} dentre os modelos apresentados nas últimas seções,
e o LiveBench \cite{livebench2025} também o coloca entre os melhores, ainda mais comparando com os \textit{open source}.

\subsection{Conclusão}
Por se tratar de um modelo estado da arte dentro das opções de resposta rápida e possuir limites aceitáveis,
a escolha do uso do Gemini 2.5 Flash foi a natural.
No caso da Mistral, seus limites são bem mais do que o suficiente para a aplicação, 
mas a sua performance não é tão boa, logo não foi escolhida.
Cerebras foi descartada rapidamente por não dar acesso por API ao envio de imagens. 
Já a Groq, apesar de ter restrições mais severas, dá acesso a dois modelos multimodais e foi considerada para uso.

Portanto, os testes utilizaram os Llama 4 Scout/Maverick disponibilizados pela Groq e o modelo da Google.

\section{Técnicas de \textit{Prompt Engineering}}
